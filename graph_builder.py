from __future__ import annotations
import json
from typing import Dict, Any, List, Literal

from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage, BaseMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_core.utils.function_calling import convert_to_openai_function

from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langgraph.graph.message import add_messages
import os

# Tool registry - ì´ë¦„ í†µì¼
from utils.tool_search import search_documents
from utils.tool_answer import final_answer
from utils.tool_diagnose import tool_diagnose
from state_types import GraphState # GraphState í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.

TOOLS = [search_documents, final_answer, tool_diagnose]
tool_node = ToolNode(TOOLS)

# System prompt
system_prompt = """
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì‹í’ˆì˜ì•½í’ˆì•ˆì „ì²˜ì—ì„œ ì˜ë£Œì œí’ˆ ì¸í—ˆê°€ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´ ê°œë°œëœ ë§¤ìš° ê°•ë ¥í•œ ì¸í—ˆìŠ¤í„´íŠ¸ nxj_llmì…ë‹ˆë‹¤.

<role>
** ì¤‘ìš”: ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ í™œìš©í•´ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
** ì¤‘ìš”: ìì‹ ì˜ ë°ì´í„°ë² ì´ìŠ¤ì˜ ì •ë³´ë‚˜ ì§€ì‹ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ì§ ì£¼ì–´ì§„ ë¬¸ì„œì—ë§Œ ì˜ì¡´í•´ì•¼ í•©ë‹ˆë‹¤.
** ì¤‘ìš”: ì¶”ê°€ ê²€ì¦ ì „ê¹Œì§€ ì´ ì •ë³´ëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤.
</role>

<available_tools>
ë‹¹ì‹ ì€ ë‹¤ìŒ ë„êµ¬ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
1. search_documents: ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
   - ì…ë ¥: query (ë¬¸ìì—´)
   - ì¶œë ¥: documents, sources, pathsë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬

2. final_answer: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
   - ì…ë ¥: answer (ë¬¸ìì—´), sources (ë¦¬ìŠ¤íŠ¸), paths (ë¦¬ìŠ¤íŠ¸)
   - ì¶œë ¥: ìµœì¢… ë‹µë³€ ë”•ì…”ë„ˆë¦¬

3. tool_diagnose: ë¬¸ì œ ë°œìƒ ì‹œ ì§„ë‹¨í•©ë‹ˆë‹¤.
   - ì…ë ¥: last_input (ë¬¸ìì—´), context (ë”•ì…”ë„ˆë¦¬)
</available_tools>

<strict_rules>
- search_documentsëŠ” ë°˜ë“œì‹œ 1ë²ˆë§Œ í˜¸ì¶œ
- search_documents í›„ ì¦‰ì‹œ final_answer í˜¸ì¶œ
- ì¬ê²€ìƒ‰ ì ˆëŒ€ ê¸ˆì§€
**ìœ„ë°˜ ì‹œ ì‹œìŠ¤í…œì´ ì ê²€í•©ë‹ˆë‹¤.**
</strict_rules>

<instructions>
1. ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ìœ¼ë©´ ë¨¼ì € search_documentsë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”.
2. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
3. final_answer ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.
4. ë¬¸ì„œì— ì •ë³´ê°€ ì—†ìœ¼ë©´ ê·¸ ì‚¬ì‹¤ì„ ëª…ì‹œí•˜ì„¸ìš”.
** ìµœì¢… ë‹µë³€ ì‹œì— '+', '.json' ë¬¸ìì—´ì€ ì œê±°í•˜ì„¸ìš”. **
</instructions>
"""

# LLM setup with function calling
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0,
    max_tokens=2048,
).bind_tools(TOOLS)

# Agent node
def agent(state: GraphState) -> Dict[str, Any]:
    """LLMì´ ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•˜ëŠ” ë…¸ë“œ"""
    messages = state.get("messages", [])
    
    print("DEBUG: Agent node received messages (before LLM invoke):")
    for i, msg in enumerate(messages):
        tool_calls_info = getattr(msg, 'tool_calls', 'N/A')
        print(f"  [{i}] Type: {type(msg).__name__}, Role: {msg.type}, Content: {str(msg.content)[:70]}..., Tool Calls: {tool_calls_info}")
    
    response = llm.invoke(messages)
    
    print(f"DEBUG: LLM Response type: {type(response)}")
    print(f"DEBUG: LLM Response content: {response.content[:70]}...")
    print(f"DEBUG: LLM Response additional_kwargs: {response.additional_kwargs}")
    
    updated_messages = add_messages(messages, response)
    
    new_state = state.copy()
    new_state["messages"] = updated_messages
    
    print("DEBUG: Agent node returning state with updated messages.")
    return new_state

# Router function
def should_continue(state: GraphState) -> Literal["tools", "end"]:
    """ë‹¤ìŒ ë…¸ë“œë¥¼ ê²°ì •í•˜ëŠ” ë¼ìš°í„°"""
    messages = state.get("messages", [])
    last_message = messages[-1] if messages else None
    
    if last_message and isinstance(last_message, AIMessage) and last_message.tool_calls:
        print("DEBUG: Router decided: tools (AIMessage with tool_calls detected)")
        return "tools"
    
    print("DEBUG: Router decided: end (no tool_calls detected or final answer)")
    return "end"

# Result processor
def process_result(state: GraphState) -> Dict[str, Any]:
    """ìµœì¢… ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë…¸ë“œ"""
    messages = state.get("messages", [])
    
    if "answer" in state and state["answer"]:
        return {
            "messages": messages,
            "answer": state["answer"],
            "sources": state.get("sources", []),
            "paths": state.get("paths", [])
        }

    for message in reversed(messages):
        if isinstance(message, AIMessage) and message.content:
            return {
                "messages": messages,
                "answer": message.content,
                "sources": state.get("sources", []),
                "paths": state.get("paths", [])
            }
    
    return {
        "messages": messages,
        "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "sources": state.get("sources", []),
        "paths": state.get("paths", [])
    }

# Tool result handler
def handle_tool_result(state: GraphState) -> Dict[str, Any]:
    """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ Stateì— ë°˜ì˜"""
    messages = state.get("messages", []) # ë…¸ë“œê°€ ë°›ì€ í˜„ì¬ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    print("DEBUG: handle_tool_result received state messages:")
    for i, msg in enumerate(messages):
        tool_calls_info = getattr(msg, 'tool_calls', 'N/A')
        print(f"  [{i}] Type: {type(msg).__name__}, Role: {msg.type}, Content: {str(msg.content)[:70]}..., Tool Calls: {tool_calls_info}")

    new_state = state.copy() # í˜„ì¬ ìƒíƒœë¥¼ ë³µì‚¬í•©ë‹ˆë‹¤.
    # new_state["messages"] = messages # ì´ ì¤„ì€ ì•„ë˜ì—ì„œ ì¡°ê±´ë¶€ë¡œ ì—…ë°ì´íŠ¸ë˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ì œê±°í•©ë‹ˆë‹¤.

    if messages and isinstance(messages[-1], ToolMessage):
        try:
            content = messages[-1].content
            if isinstance(content, str) and content.strip().startswith("{") and content.strip().endswith("}"):
                result = json.loads(content)
                
                # ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ëŠ” ToolNodeì— ì˜í•´ ì´ë¯¸ ì—…ë°ì´íŠ¸ë˜ì—ˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ë‹¤ë¥¸ í•„ë“œë§Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
                # ê·¸ë¦¬ê³  ë°˜ë“œì‹œ messages í•„ë“œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
                if "documents" in result:
                    new_state["documents"] = result.get("documents", [])
                    new_state["sources"] = result.get("sources", [])
                    new_state["paths"] = result.get("paths", [])
                    print(f"DEBUG: handle_tool_result updated documents/sources/paths. Docs: {len(new_state['documents'])}")
                
                if "answer" in result:
                    new_state["answer"] = result.get("answer", "")
                    new_state["sources"] = result.get("sources", [])
                    new_state["paths"] = result.get("paths", [])
                    print(f"DEBUG: handle_tool_result updated answer: {new_state['answer'][:70]}...")
            else:
                print(f"DEBUG: handle_tool_result received non-JSON or empty content: '{content[:50]}...'")
        except json.JSONDecodeError as e:
            print(f"ERROR: handle_tool_result failed to parse JSON: {e}")
            print(f"ERROR: Problematic content (last ToolMessage): {messages[-1].content[:100]}...")
            import traceback
            traceback.print_exc()
        except Exception as e:
            print(f"ERROR: An unexpected error occurred in handle_tool_result: {e}")
            import traceback
            traceback.print_exc()
    else:
        print("DEBUG: handle_tool_result did not find ToolMessage as last message or messages list was empty.")
    
    # ì´ ë…¸ë“œì—ì„œ messages í•„ë“œë¥¼ ì§ì ‘ ë³€ê²½í•˜ì§€ëŠ” ì•Šì•˜ì§€ë§Œ,
    # ë‹¤ìŒ ë…¸ë“œ(agent)ë¡œ ì „ë‹¬ë  ë•Œ messages í•„ë“œê°€ ì˜¬ë°”ë¥´ê²Œ ìœ ì§€ë˜ë„ë¡ ëª…ì‹œì ìœ¼ë¡œ í• ë‹¹í•©ë‹ˆë‹¤.
    # ToolNodeê°€ messagesë¥¼ ì´ë¯¸ ì—…ë°ì´íŠ¸í–ˆìœ¼ë¯€ë¡œ, ê·¸ ìƒíƒœë¥¼ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    new_state["messages"] = messages 

    print("DEBUG: handle_tool_result returning state messages:")
    for i, msg in enumerate(new_state["messages"]):
        print(f"  [{i}] Type: {type(msg).__name__}, Role: {msg.type}, Content: {str(msg.content)[:70]}...")
        if hasattr(msg, 'tool_calls') and msg.tool_calls:
            print(f"    Tool Calls: {msg.tool_calls}")
        if hasattr(msg, 'tool_call_id') and msg.tool_call_id:
            print(f"    Tool Call ID: {msg.tool_call_id}")

    return new_state # ë³€ê²½ëœ new_stateë¥¼ ë°˜í™˜

# Build graph
workflow = StateGraph(GraphState)

# Add nodes
workflow.add_node("agent", agent)
workflow.add_node("tools", tool_node)
workflow.add_node("process_result", process_result)
workflow.add_node("handle_tool_result", handle_tool_result)

# Set entry point
workflow.set_entry_point("agent")

# Add edges
workflow.add_conditional_edges(
    "agent",
    should_continue,
    {
        "tools": "tools",
        "end": "process_result"
    }
)

workflow.add_edge("tools", "handle_tool_result")
workflow.add_edge("handle_tool_result", "agent") # ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ agentê°€ ë‹¤ìŒ í–‰ë™ ê²°ì •

workflow.add_edge("process_result", END)

try:
    app = workflow.compile()
    print(f"DEBUG: app after compile: {app}")
    if app is None:
        print("ERROR: workflow.compile()ì´ Noneì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. ê·¸ë˜í”„ ì»´íŒŒì¼ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        raise RuntimeError("LangGraph ì»´íŒŒì¼ ì‹¤íŒ¨: appì´ Noneì…ë‹ˆë‹¤.")
except Exception as e:
    print(f"CRITICAL ERROR: workflow.compile() ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
    import traceback
    traceback.print_exc()
    raise

# Simple interface
def respond(state: dict) -> dict:
    """
    ê°„ë‹¨í•œ ì¸í„°í˜ì´ìŠ¤ í•¨ìˆ˜
    """
    # ì…ë ¥ ê²€ì¦
    messages_input = state.get("messages", [])
    query = state.get("query", "") or state.get("last_user", "")
    
    # messages_inputì´ ë¹„ì–´ìˆìœ¼ë©´ ìƒˆë¡œ ì‹œì‘í•˜ëŠ” ëŒ€í™”ì´ë¯€ë¡œ SystemMessageì™€ HumanMessageë¥¼ ì¶”ê°€
    if not messages_input:
        if query:
            messages_input = [SystemMessage(content=system_prompt), HumanMessage(content=query)]
        else: # queryë„ ì—†ê³  messagesë„ ì—†ìœ¼ë©´ ì˜¤ë¥˜
            return {
                "messages": [],
                "output": "âŒ ì…ë ¥ ì˜¤ë¥˜: ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.",
                "answer": "",
                "sources": [],
                "paths": []
            }
    else:
        # ê¸°ì¡´ ë©”ì‹œì§€ê°€ ìˆì§€ë§Œ SystemMessageê°€ ì²« ë©”ì‹œì§€ê°€ ì•„ë‹ˆê±°ë‚˜ ë‚´ìš©ì´ ë‹¤ë¥´ë©´ ì¶”ê°€/êµì²´
        if not isinstance(messages_input[0], SystemMessage) or messages_input[0].content != system_prompt:
            messages_input = [SystemMessage(content=system_prompt)] + messages_input
    
    # ì´ˆê¸° ìƒíƒœ ì„¤ì •
    initial_state: GraphState = {
        "messages": messages_input,
        "documents": state.get("documents", []), # ê¸°ì¡´ ìƒíƒœì˜ documents, sources, paths ìœ ì§€
        "sources": state.get("sources", []),
        "paths": state.get("paths", []),
        "answer": state.get("answer", "")
    }
    
    print("DEBUG: Initial state for Graph execution (respond function entry):")
    for i, msg in enumerate(initial_state["messages"]):
        print(f"  [{i}] Type: {type(msg).__name__}, Role: {msg.type}, Content: {str(msg.content)[:70]}...")
        if hasattr(msg, 'tool_calls') and msg.tool_calls:
            print(f"    Tool Calls: {msg.tool_calls}")
        if hasattr(msg, 'tool_call_id') and msg.tool_call_id:
            print(f"    Tool Call ID: {msg.tool_call_id}")
                
    try:
        result: GraphState = app.invoke(initial_state)
        
        answer = result.get("answer", "")
        sources = result.get("sources", [])
        paths = result.get("paths", [])

        if not answer:
            for msg in reversed(result.get("messages", [])):
                if isinstance(msg, AIMessage) and msg.content:
                    answer = msg.content
                    break
        
        if not answer:
            answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return {
            "messages": result.get("messages", []),
            "output": answer,
            "answer": answer,
            "sources": sources,
            "paths": paths
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        
        diagnosis_result = tool_diagnose._run(
            last_input=query,
            context={"error": str(e), "state": initial_state}
        )
        
        try:
            parsed_diagnosis = json.loads(diagnosis_result)
            diagnosis_str = f"ğŸ” ì§„ë‹¨ ê²°ê³¼:\\n{parsed_diagnosis.get('diagnosis', 'ì§„ë‹¨ ì •ë³´ ì—†ìŒ')}\\n\\nâœ… ê¶Œì¥ ì‚¬í•­:\\n{parsed_diagnosis.get('recommendations', 'ê¶Œì¥ ì‚¬í•­ ì—†ìŒ')}"
        except json.JSONDecodeError:
            diagnosis_str = f"ğŸ” ì§„ë‹¨ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {diagnosis_result}"

        return {
            "messages": messages_input,
            "output": f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {str(e)}\\n\\n{diagnosis_str}",
            "answer": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ì§„ë‹¨ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
            "sources": [],
            "paths": []
        }
